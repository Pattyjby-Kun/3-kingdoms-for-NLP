import os
import json
from pythainlp.tokenize import sent_tokenize

# üîπ Path ‡∏Ç‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
CHARACTER_LIST_PATH = r"C:\Homework\3-kingdoms-for-NLP\data\character_list.json"
INPUT_DIR = r"C:\Homework\3-kingdoms-for-NLP\data\cleaned"
OUTPUT_DIR = r"C:\Homework\3-kingdoms-for-NLP\output\chapter_relations_rulebased"

# üîπ ‡∏Ñ‡∏≥‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå
RELATION_KEYWORDS = {
    "‡∏û‡∏µ‡πà‡∏ô‡πâ‡∏≠‡∏á": ["‡∏™‡∏≤‡∏ö‡∏≤‡∏ô", "‡∏£‡πà‡∏ß‡∏°‡∏Ñ‡∏≥‡∏™‡∏±‡∏ï‡∏¢‡πå", "‡∏û‡∏µ‡πà‡∏ô‡πâ‡∏≠‡∏á", "‡∏™‡∏´‡∏≤‡∏¢"],
    "‡∏®‡∏±‡∏ï‡∏£‡∏π": ["‡∏£‡∏ö‡∏Å‡∏±‡∏ö", "‡∏ï‡πà‡∏≠‡∏™‡∏π‡πâ‡∏Å‡∏±‡∏ö", "‡∏ó‡∏≥‡∏®‡∏∂‡∏Å‡∏Å‡∏±‡∏ö", "‡∏®‡∏±‡∏ï‡∏£‡∏π", "‡∏Ü‡πà‡∏≤", "‡∏à‡∏±‡∏ö‡∏ï‡∏±‡∏ß", "‡∏ó‡∏≥‡∏£‡πâ‡∏≤‡∏¢"],
    "‡∏û‡∏±‡∏ô‡∏ò‡∏°‡∏¥‡∏ï‡∏£": ["‡∏£‡πà‡∏ß‡∏°‡∏£‡∏ö", "‡∏ä‡πà‡∏ß‡∏¢", "‡πÄ‡∏Ç‡πâ‡∏≤‡∏£‡πà‡∏ß‡∏°", "‡∏¢‡∏Å‡∏ó‡∏±‡∏û‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô", "‡∏™‡∏π‡πâ‡∏£‡πà‡∏ß‡∏°‡∏Å‡∏±‡∏ô", "‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏´‡∏•‡∏∑‡∏≠"],
    "‡πÄ‡∏à‡πâ‡∏≤‡∏ô‡∏≤‡∏¢-‡∏•‡∏π‡∏Å‡∏ô‡πâ‡∏≠‡∏á": ["‡∏£‡∏±‡∏ö‡πÉ‡∏ä‡πâ", "‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∂‡∏Å‡∏©‡∏≤", "‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á", "‡∏ñ‡∏ß‡∏≤‡∏¢", "‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥", "‡∏õ‡∏£‡∏∂‡∏Å‡∏©‡∏≤", "‡∏ü‡∏±‡∏á‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á"]
}


def find_relations_rulebased(file_path, characters):
    """
    ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏Ç‡∏≠‡∏á‡∏ï‡∏±‡∏ß‡∏•‡∏∞‡∏Ñ‡∏£‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° ‡πÇ‡∏î‡∏¢‡∏≠‡∏¥‡∏á keyword rule
    """
    with open(file_path, "r", encoding="utf-8") as f:
        text = f.read()

    sentences = sent_tokenize(text)
    relations = []

    for sent in sentences:
        # ‡∏´‡∏≤‡πÉ‡∏Ñ‡∏£‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏ô‡∏µ‡πâ‡∏ö‡πâ‡∏≤‡∏á
        found = [c for c in characters if c in sent]
        if len(found) >= 2:
            # ‡∏°‡∏µ‡∏ï‡∏±‡∏ß‡∏•‡∏∞‡∏Ñ‡∏£‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ 1 ‡∏Ñ‡∏ô‡πÉ‡∏ô‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ
            for rel_type, keywords in RELATION_KEYWORDS.items():
                if any(k in sent for k in keywords):
                    for i in range(len(found)):
                        for j in range(i + 1, len(found)):
                            relation_data = {
                                "character_1": found[i],
                                "relationship": rel_type,
                                "character_2": found[j],
                                "sentence": sent.strip()
                            }
                            relations.append(relation_data)

    return relations


def run_rulebased():
    # ‡πÇ‡∏´‡∏•‡∏î‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡∏ï‡∏±‡∏ß‡∏•‡∏∞‡∏Ñ‡∏£‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå JSON
    if not os.path.exists(CHARACTER_LIST_PATH):
        raise FileNotFoundError(f"‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ï‡∏±‡∏ß‡∏•‡∏∞‡∏Ñ‡∏£: {CHARACTER_LIST_PATH}")

    with open(CHARACTER_LIST_PATH, "r", encoding="utf-8") as f:
        characters = json.load(f)["characters"]

    # ‡∏ï‡∏£‡∏ß‡∏à‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå output
    os.makedirs(OUTPUT_DIR, exist_ok=True)

    print("üîç ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡πÅ‡∏ö‡∏ö Rule-based...\n")

    for file in sorted(os.listdir(INPUT_DIR)):
        if not file.endswith("_cleaned.txt"):
            continue

        file_path = os.path.join(INPUT_DIR, file)
        relations = find_relations_rulebased(file_path, characters)

        # üî∏ ‡∏Å‡∏£‡∏≠‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏ã‡πâ‡∏≥ (‡πÄ‡∏•‡πà‡∏≤‡∏õ‡∏µ‡πà‚Äì‡∏Å‡∏ß‡∏ô‡∏≠‡∏π vs ‡∏Å‡∏ß‡∏ô‡∏≠‡∏π‚Äì‡πÄ‡∏•‡πà‡∏≤‡∏õ‡∏µ‡πà)
        unique_relations = []
        seen_pairs = set()
        for rel in relations:
            pair = tuple(sorted([rel["character_1"], rel["character_2"], rel["relationship"]]))
            if pair not in seen_pairs:
                seen_pairs.add(pair)
                unique_relations.append(rel)

        # üî∏ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
        output_path = os.path.join(
            OUTPUT_DIR, file.replace("_cleaned.txt", "_relations_rulebased.json")
        )
        with open(output_path, "w", encoding="utf-8") as f:
            json.dump(unique_relations, f, ensure_ascii=False, indent=4)

        print(f"‚úÖ {file}: ‡∏û‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå {len(unique_relations)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")

    print("\nüéâ ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß! ‡∏î‡∏π‡∏ú‡∏•‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå:")
    print(OUTPUT_DIR)


if __name__ == "__main__":
    run_rulebased()
